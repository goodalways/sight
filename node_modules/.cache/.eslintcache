[{"/Users/jonathanyap/Downloads/sight/src/index.js":"1","/Users/jonathanyap/Downloads/sight/src/reportWebVitals.js":"2","/Users/jonathanyap/Downloads/sight/src/App.js":"3","/Users/jonathanyap/Downloads/sight/src/WebcamImage.js":"4","/Users/jonathanyap/Downloads/sight/src/Components/Sidebar.js":"5","/Users/jonathanyap/Downloads/Revised Sight/sight/src/index.js":"6","/Users/jonathanyap/Downloads/Revised Sight/sight/src/App.js":"7","/Users/jonathanyap/Downloads/Revised Sight/sight/src/reportWebVitals.js":"8","/Users/jonathanyap/Downloads/Revised Sight/sight/src/firebaseConfig.js":"9","/Users/jonathanyap/Downloads/Revised Sight/sight/src/Conversations.js":"10","/Users/jonathanyap/Downloads/Revised Sight/sight/src/Components/Navbar.js":"11","/Users/jonathanyap/Downloads/Revised Sight/sight/src/HomePage.js":"12"},{"size":535,"mtime":1700874221234,"results":"13","hashOfConfig":"14"},{"size":362,"mtime":1699312634000,"results":"15","hashOfConfig":"14"},{"size":5139,"mtime":1700874252502,"results":"16","hashOfConfig":"14"},{"size":1081,"mtime":1700008880541,"results":"17","hashOfConfig":"18"},{"size":156,"mtime":1700872541150,"results":"19","hashOfConfig":"14"},{"size":1009,"mtime":1701048652142,"results":"20","hashOfConfig":"21"},{"size":7931,"mtime":1701047159064,"results":"22","hashOfConfig":"21"},{"size":362,"mtime":1699312634000,"results":"23","hashOfConfig":"21"},{"size":572,"mtime":1700971254053,"results":"24","hashOfConfig":"21"},{"size":2348,"mtime":1700982745199,"results":"25","hashOfConfig":"21"},{"size":1962,"mtime":1701049345663,"results":"26","hashOfConfig":"21"},{"size":692,"mtime":1701049226026,"results":"27","hashOfConfig":"21"},{"filePath":"28","messages":"29","suppressedMessages":"30","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"1x565ah",{"filePath":"31","messages":"32","suppressedMessages":"33","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"34"},{"filePath":"35","messages":"36","suppressedMessages":"37","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"38","messages":"39","suppressedMessages":"40","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"49s5ws",{"filePath":"41","messages":"42","suppressedMessages":"43","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"34"},{"filePath":"44","messages":"45","suppressedMessages":"46","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"47"},"19qsgv9",{"filePath":"48","messages":"49","suppressedMessages":"50","errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"51","usedDeprecatedRules":"52"},{"filePath":"53","messages":"54","suppressedMessages":"55","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"52"},{"filePath":"56","messages":"57","suppressedMessages":"58","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"52"},{"filePath":"59","messages":"60","suppressedMessages":"61","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"62","usedDeprecatedRules":"52"},{"filePath":"63","messages":"64","suppressedMessages":"65","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"66","messages":"67","suppressedMessages":"68","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/jonathanyap/Downloads/sight/src/index.js",[],[],"/Users/jonathanyap/Downloads/sight/src/reportWebVitals.js",[],[],["69","70","71","72","73","74"],"/Users/jonathanyap/Downloads/sight/src/App.js",["75"],[],"/Users/jonathanyap/Downloads/sight/src/WebcamImage.js",[],[],"/Users/jonathanyap/Downloads/sight/src/Components/Sidebar.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/index.js",[],[],["76","77","78","79","80","81"],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/App.js",["82","83"],[],"import React, { useRef, useState, /*useCallback*/ } from 'react';\nimport './App.css';\nimport Navbar from './Components/Navbar';\nimport Webcam from \"react-webcam\";\nimport { useSpeechRecognition, useSpeechSynthesis } from 'react-speech-kit';\nimport { imageDb, textDb } from './firebaseConfig';\nimport { ref, uploadString } from 'firebase/storage';\nimport { addDoc, collection, doc, updateDoc } from 'firebase/firestore';\nimport { v4 } from 'uuid';\n\n\nfunction App() {\n  const newDate = new Date();\n  const date = newDate.getDate();\n  const month = newDate.getMonth() + 1;\n  const year = newDate.getFullYear();\n  const hour = newDate.getHours();\n  const minute = newDate.getMinutes();\n  const second = newDate.getSeconds();\n\n  const [speechValue, setSpeechValue] = useState('')\n  // const { listen, listening, stop } = useSpeechRecognition({\n  //   onResult: (speechResult) => {\n  //     setSpeechValue(speechResult)\n  //   }\n  // })\n\n  const onEnd = () => {\n    // You could do something here after listening has finished\n  };\n\n  const onResult = (speechResult) => {\n    setSpeechValue(speechResult);\n  };\n\n  const onError = (event) => {\n    if (event.error === 'not-allowed') {\n      setBlocked(true);\n    }\n  };\n\n  const { listen, listening, stop } = useSpeechRecognition({\n    onResult,\n    onEnd,\n    onError,\n  });\n\n  const toggle = listening\n    ? stop\n    : () => {\n        setBlocked(false);\n        listen();\n      };\n\n    const { speak, cancel, speaking } = useSpeechSynthesis({\n      onEnd,\n    });\n\n  const [img, setImg] = useState(null);\n  const webcamRef = useRef(null);\n  const [apiResult, setAPIResult] = useState('');\n  const [statusMessage, setStatusMessage] = useState('');\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [prompt, setPrompt] = useState('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.');\n  const [blocked, setBlocked] = useState(false);\n  const [dataId, setDataId] = useState('');\n\n  const videoConstraints = {\n    width: 420,\n    height: 420,\n    facingMode: \"environment\",\n  };\n\n  // const capture = useCallback(() => {\n  //   const imageSrc = webcamRef.current.getScreenshot();\n  //   setImg(imageSrc);\n  //   setStatusMessage('Sending request...');\n  //   setUploadProgress(10); // Initial progress\n  //   // eslint-disable-next-line react-hooks/exhaustive-deps\n  //   callGPT4(imageSrc, prompt); \n  // }, [webcamRef]);\n\n  const capture = () => {\n    const imageSrc = webcamRef.current.getScreenshot();\n    setImg(imageSrc);\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    callGPT4(imageSrc, prompt); \n    uploadPhoto(imageSrc);\n  }\n\n  const talkmethod = (textToRead) => {\n    const msg = new SpeechSynthesisUtterance();\n    msg.text = textToRead;\n    window.speechSynthesis.speak(msg);\n  }\n\n  const callGPT4 = async (imageString, promptToSend) => {\n    const base64String = imageString.replace('data:', '').replace(/^.+,/, '');\n\n    const data = {\n      model: \"gpt-4-vision-preview\",\n      messages: [\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\n              \"type\": \"text\",\n              \"text\": promptToSend\n            },\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": `data:image/jpeg;base64,${base64String}`\n              }\n            }\n          ]\n        }\n      ],\n      max_tokens: 10\n    };\n\n    try {\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${process.env.REACT_APP_OPENAI_API_KEY}` // Use environment variable for API key\n        },\n        body: JSON.stringify(data)\n      });\n      setUploadProgress(50); // Midway progressgit\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      const apiResponse = await response.json();\n      setUploadProgress(100); // Final progress\n      if (apiResponse.choices && apiResponse.choices.length > 0) {\n        talkmethod(apiResponse.choices[0].message.content);\n        setAPIResult(apiResponse.choices[0].message.content);\n        setStatusMessage('Analysis complete.');     \n      } else {\n        console.error('No choices returned from API');\n        setStatusMessage('Failed to get a response from the API.');\n      }\n    } catch (error) {\n      console.error('Error:', error);\n      alert(error);\n      alert(process.env.REACT_APP_OPENAI_API_KEY);\n      setStatusMessage('An error occurred during the analysis.');\n    }\n  };\n\n  const sendNewPrompt = () => {\n    const newPrompt = prompt + '\\n\\n' + apiResult + '\\n\\n' + speechValue\n    setPrompt(newPrompt)\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    callGPT4(img, newPrompt)\n    updateData(newPrompt)\n    //alert(newPrompt)\n  };\n\n  const retakeMethod = () => {\n    setImg(null)\n    setStatusMessage('')\n    setAPIResult('')\n    setUploadProgress(0)\n    setPrompt('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.')\n    setSpeechValue('')\n  }\n\n  const uploadPhoto = (imageSrc) => {\n    const currentFileName = v4()+'.jpg';\n    const imgRef = ref(imageDb, `uploads/${currentFileName}`);\n    uploadString(imgRef, imageSrc, 'data_url');\n    uploadData(imageSrc);\n  }\n\n  const dbValue = collection(textDb, 'conversations');\n  const uploadData = async (image) => {\n    await addDoc(dbValue, {filePath:image, conversation:prompt, dateCreated:`${year}-${month<10?`0${month}`:`${month}`}-${date}` + \" \" + `${hour}:${minute}:${second}`}).then((docRef) => {\n      setDataId(docRef.id);\n    });\n  }\n  \n  const updateData = async (newPrompt) => {\n    const updateDBRef = doc(textDb, 'conversations', dataId);\n    await updateDoc(updateDBRef, {conversation:newPrompt});\n  }\n\n  return (\n    <div className=\"App\">\n      <Navbar />\n      <div className=\"Container\">\n      <h1>Sight</h1>\n      {img === null ? (\n        <>\n          <Webcam\n            audio={false}\n            mirrored={false}\n            height={400}\n            width={400}\n            ref={webcamRef}\n            screenshotFormat=\"image/jpeg\"\n            videoConstraints={videoConstraints}\n          />\n          <button onClick={capture}>Capture photo</button>\n        </>\n      ) : (\n        <>\n          <img src={img} alt=\"screenshot\" />\n          <button onClick={retakeMethod}>Retake</button>\n        </>\n      )}\n      {speaking ? (\n        <button type=\"button\" onClick={cancel}>\n          Stop\n        </button>\n      ) : (\n        <button\n          type=\"button\"\n          onClick={() => speak({text: apiResult})}\n        >\n          Speak\n        </button>\n      )}\n      \n      {statusMessage && <p className=\"status-message\">{statusMessage}</p >}\n      {uploadProgress > 0 && (\n        <progress value={uploadProgress} max=\"100\"></progress>\n      )} \n      <p></p>\n      {apiResult && (\n        <div className=\"result\">\n          <strong>Analysis Result:</strong>\n          <textarea value={apiResult} readOnly />\n        </div>\n      )}\n\n      <div className=\"result\">\n       <textarea\n         value={speechValue}\n         onChange={(event) => setSpeechValue(event.target.value)}\n        />\n        {/* <button onMouseDown={listen} onMouseUp={stop}>\n          🎤\n        </button> */}\n\n        <button disabled={blocked} type=\"button\" onClick={toggle}>\n          {listening ? 'Stop' : 'Listen'}\n        </button>\n\n        <button onClick={sendNewPrompt}>\n          Tell me more\n        </button>\n        {/* <button onClick={uploadData} /> */}\n       </div>\n    </div>   \n  </div>\n  );\n}\nexport default App;",["84","85","86","87","88","89"],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/reportWebVitals.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/firebaseConfig.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/Conversations.js",["90"],[],"import React, { useState, useEffect } from 'react';\nimport './App.css';\nimport Navbar from './Components/Navbar';\nimport { imageDb, textDb } from './firebaseConfig';\nimport { getDownloadURL, listAll, ref } from 'firebase/storage';\nimport { getDocs, collection } from 'firebase/firestore';\n\nfunction Conversations() {\n    \n    const [imgUrl, setImgUrl] = useState([]);\n    const [data, setData] = useState([]);\n    useEffect(() => {\n        listAll(ref(imageDb,\"uploads\")).then(imgs => {            \n                imgs.items.forEach(img => {\n                getDownloadURL(img).then(url => {\n                    setImgUrl(data => [...data, url])\n                })\n            })\n        })\n    },[]);\n    console.log(imgUrl, \"imgUrl\");\n\n    const dbValue = collection(textDb, 'conversations');\n    const getData = async () => {\n        const dataDb = await getDocs(dbValue);\n        const listOfData = dataDb.docs.map(val => ({...val.data(),id:val.id}));\n        setData(listOfData);\n    }\n\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n    useEffect(() => {\n        getData();\n    },[]);\n\n    return (\n        <div className='conversations'>\n            <Navbar />\n            {/* {\n                imgUrl.map(dataVal => \n                    <div className='Container'>\n                        <img src={dataVal} height=\"200\" width=\"200\" alt=\"screenshot\" />\n                        <br></br>    \n                        {\n                            dataVal.split(\"https://firebasestorage.googleapis.com/v0/b/sight-26775.appspot.com/o/uploads%2\")[1].split(\"?alt=media&token=\")[0] === 'Fecc928a4-10c5-4fc0-92b7-66537693da05.jpg' ? (\n                                <button>Nothing</button>\n                            ) : (\n                                <button>{dataVal}</button>\n                            )\n                        }\n                    </div>)\n            } */}\n            {\n                data.map(value=>\n                    <div className='Container'>\n                        <img src={value.filePath} height=\"200\" width=\"200\" alt=\"screenshot\" />\n                        <h4>{value.conversation}</h4>\n                        <br></br>\n                        <h4>{value.dateCreated}</h4>\n                    </div>\n                    )\n            }\n        </div>\n    )\n}\n\nexport default Conversations;","/Users/jonathanyap/Downloads/Revised Sight/sight/src/Components/Navbar.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/HomePage.js",[],[],{"ruleId":"91","replacedBy":"92"},{"ruleId":"93","replacedBy":"94"},{"ruleId":"95","replacedBy":"96"},{"ruleId":"97","replacedBy":"98"},{"ruleId":"99","replacedBy":"100"},{"ruleId":"101","replacedBy":"102"},{"ruleId":"103","severity":1,"message":"104","line":33,"column":6,"nodeType":"105","endLine":33,"endColumn":17,"suggestions":"106"},{"ruleId":"91","replacedBy":"107"},{"ruleId":"93","replacedBy":"108"},{"ruleId":"95","replacedBy":"109"},{"ruleId":"97","replacedBy":"110"},{"ruleId":"99","replacedBy":"111"},{"ruleId":"101","replacedBy":"112"},{"ruleId":"113","severity":1,"message":"114","line":182,"column":130,"nodeType":"115","messageId":"116","endLine":182,"endColumn":131},{"ruleId":"113","severity":1,"message":"114","line":182,"column":136,"nodeType":"115","messageId":"116","endLine":182,"endColumn":137},{"ruleId":"91","replacedBy":"117"},{"ruleId":"93","replacedBy":"118"},{"ruleId":"95","replacedBy":"119"},{"ruleId":"97","replacedBy":"120"},{"ruleId":"99","replacedBy":"121"},{"ruleId":"101","replacedBy":"122"},{"ruleId":"103","severity":1,"message":"123","line":33,"column":7,"nodeType":"105","endLine":33,"endColumn":9,"suggestions":"124"},"dot-location",[],"new-parens",[],"no-mixed-operators",[],"no-new-object",["125"],"no-whitespace-before-property",[],"rest-spread-spacing",[],"react-hooks/exhaustive-deps","React Hook useCallback has missing dependencies: 'callGPT4' and 'prompt'. Either include them or remove the dependency array.","ArrayExpression",["126"],[],[],[],["125"],[],[],"no-useless-concat","Unexpected string concatenation of literals.","BinaryExpression","unexpectedConcat",[],[],[],["125"],[],[],"React Hook useEffect has a missing dependency: 'getData'. Either include it or remove the dependency array.",["127"],"no-object-constructor",{"desc":"128","fix":"129"},{"desc":"130","fix":"131"},"Update the dependencies array to be: [callGPT4, prompt]",{"range":"132","text":"133"},"Update the dependencies array to be: [getData]",{"range":"134","text":"135"},[1188,1199],"[callGPT4, prompt]",[1100,1102],"[getData]"]