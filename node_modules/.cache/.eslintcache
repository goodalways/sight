[{"/Users/jonathanyap/Downloads/sight/src/index.js":"1","/Users/jonathanyap/Downloads/sight/src/reportWebVitals.js":"2","/Users/jonathanyap/Downloads/sight/src/App.js":"3","/Users/jonathanyap/Downloads/sight/src/WebcamImage.js":"4","/Users/jonathanyap/Downloads/sight/src/Components/Sidebar.js":"5","/Users/jonathanyap/Downloads/Revised Sight/sight/src/index.js":"6","/Users/jonathanyap/Downloads/Revised Sight/sight/src/App.js":"7","/Users/jonathanyap/Downloads/Revised Sight/sight/src/reportWebVitals.js":"8"},{"size":535,"mtime":1700874221234,"results":"9","hashOfConfig":"10"},{"size":362,"mtime":1699312634000,"results":"11","hashOfConfig":"10"},{"size":5139,"mtime":1700874252502,"results":"12","hashOfConfig":"10"},{"size":1081,"mtime":1700008880541,"results":"13","hashOfConfig":"14"},{"size":156,"mtime":1700872541150,"results":"15","hashOfConfig":"10"},{"size":535,"mtime":1700874221234,"results":"16","hashOfConfig":"17"},{"size":5200,"mtime":1700876351886,"results":"18","hashOfConfig":"17"},{"size":362,"mtime":1699312634000,"results":"19","hashOfConfig":"17"},{"filePath":"20","messages":"21","suppressedMessages":"22","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"1x565ah",{"filePath":"23","messages":"24","suppressedMessages":"25","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"27","messages":"28","suppressedMessages":"29","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"30","messages":"31","suppressedMessages":"32","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"49s5ws",{"filePath":"33","messages":"34","suppressedMessages":"35","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"36","messages":"37","suppressedMessages":"38","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"6a1syx",{"filePath":"39","messages":"40","suppressedMessages":"41","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"42"},{"filePath":"43","messages":"44","suppressedMessages":"45","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/jonathanyap/Downloads/sight/src/index.js",[],[],"/Users/jonathanyap/Downloads/sight/src/reportWebVitals.js",[],[],["46","47","48","49","50","51"],"/Users/jonathanyap/Downloads/sight/src/App.js",["52"],[],"/Users/jonathanyap/Downloads/sight/src/WebcamImage.js",[],[],"/Users/jonathanyap/Downloads/sight/src/Components/Sidebar.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/index.js",[],[],"/Users/jonathanyap/Downloads/Revised Sight/sight/src/App.js",["53"],[],"import React, { useRef, useState, useCallback } from 'react';\nimport './App.css';\nimport Webcam from \"react-webcam\";\nimport { useSpeechRecognition } from 'react-speech-kit';\n\nfunction App() {\n  const [speechValue, setSpeechValue] = useState('')\n  const { listen, stop } = useSpeechRecognition({\n    onResult: (speechResult) => {\n      setSpeechValue(speechResult)\n    }\n  })\n\n  const [img, setImg] = useState(null);\n  const webcamRef = useRef(null);\n  const [apiResult, setAPIResult] = useState('');\n  const [statusMessage, setStatusMessage] = useState('');\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [prompt, setPrompt] = useState('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.');\n\n  const videoConstraints = {\n    width: 420,\n    height: 420,\n    facingMode: \"user\",\n  };\n\n  const capture = useCallback(() => {\n    const imageSrc = webcamRef.current.getScreenshot();\n    setImg(imageSrc);\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n    callGPT4(imageSrc, prompt); \n  }, [webcamRef]);\n\n  const talkmethod = (textToRead) => {\n    const msg = new SpeechSynthesisUtterance();\n    msg.text = textToRead;\n    window.speechSynthesis.speak(msg);\n  }\n\n  const callGPT4 = async (imageString, promptToSend) => {\n    const base64String = imageString.replace('data:', '').replace(/^.+,/, '');\n\n    const data = {\n      model: \"gpt-4-vision-preview\",\n      messages: [\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\n              \"type\": \"text\",\n              \"text\": promptToSend\n            },\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": `data:image/jpeg;base64,${base64String}`\n              }\n            }\n          ]\n        }\n      ],\n      max_tokens: 200\n    };\n\n    try {\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${process.env.REACT_APP_OPENAI_API_KEY}` // Use environment variable for API key\n        },\n        body: JSON.stringify(data)\n      });\n      setUploadProgress(50); // Midway progressgit\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      const apiResponse = await response.json();\n      setUploadProgress(100); // Final progress\n      if (apiResponse.choices && apiResponse.choices.length > 0) {\n        talkmethod(apiResponse.choices[0].message.content);\n        setAPIResult(apiResponse.choices[0].message.content);\n        setStatusMessage('Analysis complete.');     \n      } else {\n        console.error('No choices returned from API');\n        setStatusMessage('Failed to get a response from the API.');\n      }\n    } catch (error) {\n      console.error('Error:', error);\n      alert(error);\n      alert(process.env.REACT_APP_OPENAI_API_KEY);\n      setStatusMessage('An error occurred during the analysis.');\n    }\n  };\n\n  const sendNewPrompt = () => {\n    const newPrompt = prompt + '\\n' + apiResult + '\\n' + speechValue\n    setPrompt(newPrompt)\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    callGPT4(img, newPrompt)\n    alert(newPrompt)\n  };\n\n  const retakeMethod = () => {\n    setImg(null)\n    setStatusMessage('')\n    setAPIResult('')\n    setUploadProgress(0)\n    setPrompt('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.')\n    setSpeechValue('')\n  }\n\n  return (\n    <div className=\"App\">\n      <h1>Sight</h1>\n      <div className=\"Container\">\n      {img === null ? (\n        <>\n          <Webcam\n            audio={false}\n            mirrored={false}\n            height={400}\n            width={400}\n            ref={webcamRef}\n            screenshotFormat=\"image/jpeg\"\n            videoConstraints={videoConstraints}\n          />\n          <button onClick={capture}>Capture photo</button>\n        </>\n      ) : (\n        <>\n          <img src={img} alt=\"screenshot\" />\n          <button onClick={retakeMethod}>Retake</button>\n        </>\n      )}\n    </div>\n      {statusMessage && <p className=\"status-message\">{statusMessage}</p >}\n      {uploadProgress > 0 && (\n        <progress value={uploadProgress} max=\"100\"></progress>\n      )} \n      <p></p>\n      {apiResult && (\n        <div className=\"result\">\n          <strong>Analysis Result:</strong>\n          <textarea value={apiResult} readOnly />\n        </div>\n      )}\n\n      <div className=\"result\">\n       <textarea\n         value={speechValue}\n         onChange={(event) => setSpeechValue(event.target.value)}\n        />\n        <button onMouseDown={listen} onMouseUp={stop}>\n          ðŸŽ¤\n        </button>\n        <button onClick={sendNewPrompt}>\n          Tell me more\n        </button>\n       </div>\n\n    </div>\n  );\n}\nexport default App;","/Users/jonathanyap/Downloads/Revised Sight/sight/src/reportWebVitals.js",[],[],{"ruleId":"54","replacedBy":"55"},{"ruleId":"56","replacedBy":"57"},{"ruleId":"58","replacedBy":"59"},{"ruleId":"60","replacedBy":"61"},{"ruleId":"62","replacedBy":"63"},{"ruleId":"64","replacedBy":"65"},{"ruleId":"66","severity":1,"message":"67","line":33,"column":6,"nodeType":"68","endLine":33,"endColumn":17,"suggestions":"69"},{"ruleId":"66","severity":1,"message":"67","line":34,"column":6,"nodeType":"68","endLine":34,"endColumn":17,"suggestions":"70"},"dot-location",[],"new-parens",[],"no-mixed-operators",[],"no-new-object",["71"],"no-whitespace-before-property",[],"rest-spread-spacing",[],"react-hooks/exhaustive-deps","React Hook useCallback has missing dependencies: 'callGPT4' and 'prompt'. Either include them or remove the dependency array.","ArrayExpression",["72"],["73"],"no-object-constructor",{"desc":"74","fix":"75"},{"desc":"74","fix":"76"},"Update the dependencies array to be: [callGPT4, prompt]",{"range":"77","text":"78"},{"range":"79","text":"78"},[1188,1199],"[callGPT4, prompt]",[1249,1260]]