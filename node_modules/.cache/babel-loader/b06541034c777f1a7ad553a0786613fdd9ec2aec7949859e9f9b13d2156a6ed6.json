{"ast":null,"code":"import React,{useRef,useState,useCallback,useEffect}from'react';import'./App.css';import Webcam from\"react-webcam\";import{useSpeechRecognition}from'react-speech-kit';import Sidebar from'./Components/Sidebar';import{jsx as _jsx}from\"react/jsx-runtime\";import{Fragment as _Fragment}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";function App(){const[speechValue,setSpeechValue]=useState('');const{listen,stop}=useSpeechRecognition({onResult:speechResult=>{setSpeechValue(speechResult);}});const[img,setImg]=useState(null);const webcamRef=useRef(null);const[apiResult,setAPIResult]=useState('');const[statusMessage,setStatusMessage]=useState('');const[uploadProgress,setUploadProgress]=useState(0);const[prompt,setPrompt]=useState('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.');const videoConstraints={width:420,height:420,facingMode:\"user\"};const capture=useCallback(()=>{const imageSrc=webcamRef.current.getScreenshot();setImg(imageSrc);setStatusMessage('Sending request...');setUploadProgress(10);// Initial progress\ncallGPT4(imageSrc,prompt);},[webcamRef]);const talkmethod=textToRead=>{const msg=new SpeechSynthesisUtterance();msg.text=textToRead;window.speechSynthesis.speak(msg);};const callGPT4=async(imageString,promptToSend)=>{const base64String=imageString.replace('data:','').replace(/^.+,/,'');const data={model:\"gpt-4-vision-preview\",messages:[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":promptToSend},{\"type\":\"image_url\",\"image_url\":{\"url\":\"data:image/jpeg;base64,\".concat(base64String)}}]}],max_tokens:200};try{const response=await fetch('https://api.openai.com/v1/chat/completions',{method:'POST',headers:{'Content-Type':'application/json','Authorization':\"Bearer \".concat(process.env.REACT_APP_OPENAI_API_KEY)// Use environment variable for API key\n},body:JSON.stringify(data)});setUploadProgress(50);// Midway progressgit\nif(!response.ok){throw new Error(\"HTTP error! status: \".concat(response.status));}const apiResponse=await response.json();setUploadProgress(100);// Final progress\nif(apiResponse.choices&&apiResponse.choices.length>0){talkmethod(apiResponse.choices[0].message.content);setAPIResult(apiResponse.choices[0].message.content);setStatusMessage('Analysis complete.');}else{console.error('No choices returned from API');setStatusMessage('Failed to get a response from the API.');}}catch(error){console.error('Error:',error);alert(error);alert(process.env.REACT_APP_OPENAI_API_KEY);setStatusMessage('An error occurred during the analysis.');}};const sendNewPrompt=()=>{const newPrompt=prompt+'\\n'+apiResult+'\\n'+speechValue;setPrompt(newPrompt);setStatusMessage('Sending request...');setUploadProgress(10);// Initial progress\ncallGPT4(img,newPrompt);alert(newPrompt);};const retakeMethod=()=>{setImg(null);setStatusMessage('');setAPIResult('');setUploadProgress(0);setPrompt('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.');setSpeechValue('');};return/*#__PURE__*/_jsxs(\"div\",{className:\"App\",children:[/*#__PURE__*/_jsx(\"h1\",{children:\"Sight\"}),/*#__PURE__*/_jsx(\"div\",{className:\"Container\",children:img===null?/*#__PURE__*/_jsxs(_Fragment,{children:[/*#__PURE__*/_jsx(Webcam,{audio:false,mirrored:false,height:400,width:400,ref:webcamRef,screenshotFormat:\"image/jpeg\",videoConstraints:videoConstraints}),/*#__PURE__*/_jsx(\"button\",{onClick:capture,children:\"Capture photo\"})]}):/*#__PURE__*/_jsxs(_Fragment,{children:[/*#__PURE__*/_jsx(\"img\",{src:img,alt:\"screenshot\"}),/*#__PURE__*/_jsx(\"button\",{onClick:retakeMethod,children:\"Retake\"})]})}),statusMessage&&/*#__PURE__*/_jsx(\"p\",{className:\"status-message\",children:statusMessage}),uploadProgress>0&&/*#__PURE__*/_jsx(\"progress\",{value:uploadProgress,max:\"100\"}),/*#__PURE__*/_jsx(\"p\",{}),apiResult&&/*#__PURE__*/_jsxs(\"div\",{className:\"result\",children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Analysis Result:\"}),/*#__PURE__*/_jsx(\"textarea\",{value:apiResult,readOnly:true})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"result\",children:[/*#__PURE__*/_jsx(\"textarea\",{value:speechValue,onChange:event=>setSpeechValue(event.target.value)}),/*#__PURE__*/_jsx(\"button\",{onMouseDown:listen,onMouseUp:stop,children:\"\\uD83C\\uDFA4\"}),/*#__PURE__*/_jsx(\"button\",{onClick:sendNewPrompt,children:\"Tell me more\"})]})]});}export default App;","map":{"version":3,"names":["React","useRef","useState","useCallback","useEffect","Webcam","useSpeechRecognition","Sidebar","jsx","_jsx","Fragment","_Fragment","jsxs","_jsxs","App","speechValue","setSpeechValue","listen","stop","onResult","speechResult","img","setImg","webcamRef","apiResult","setAPIResult","statusMessage","setStatusMessage","uploadProgress","setUploadProgress","prompt","setPrompt","videoConstraints","width","height","facingMode","capture","imageSrc","current","getScreenshot","callGPT4","talkmethod","textToRead","msg","SpeechSynthesisUtterance","text","window","speechSynthesis","speak","imageString","promptToSend","base64String","replace","data","model","messages","concat","max_tokens","response","fetch","method","headers","process","env","REACT_APP_OPENAI_API_KEY","body","JSON","stringify","ok","Error","status","apiResponse","json","choices","length","message","content","console","error","alert","sendNewPrompt","newPrompt","retakeMethod","className","children","audio","mirrored","ref","screenshotFormat","onClick","src","alt","value","max","readOnly","onChange","event","target","onMouseDown","onMouseUp"],"sources":["/Users/jonathanyap/Downloads/sight/src/App.js"],"sourcesContent":["import React, { useRef, useState, useCallback, useEffect } from 'react';\nimport './App.css';\nimport Webcam from \"react-webcam\";\nimport { useSpeechRecognition } from 'react-speech-kit';\nimport Sidebar from './Components/Sidebar';\n\nfunction App() {\n  const [speechValue, setSpeechValue] = useState('')\n  const { listen, stop } = useSpeechRecognition({\n    onResult: (speechResult) => {\n      setSpeechValue(speechResult)\n    }\n  })\n\n  const [img, setImg] = useState(null);\n  const webcamRef = useRef(null);\n  const [apiResult, setAPIResult] = useState('');\n  const [statusMessage, setStatusMessage] = useState('');\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [prompt, setPrompt] = useState('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.');\n\n  const videoConstraints = {\n    width: 420,\n    height: 420,\n    facingMode: \"user\",\n  };\n\n  const capture = useCallback(() => {\n    const imageSrc = webcamRef.current.getScreenshot();\n    setImg(imageSrc);\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    callGPT4(imageSrc, prompt);\n  }, [webcamRef]);\n\n  const talkmethod = (textToRead) => {\n    const msg = new SpeechSynthesisUtterance();\n    msg.text = textToRead;\n    window.speechSynthesis.speak(msg);\n  }\n\n  const callGPT4 = async (imageString, promptToSend) => {\n    const base64String = imageString.replace('data:', '').replace(/^.+,/, '');\n\n    const data = {\n      model: \"gpt-4-vision-preview\",\n      messages: [\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\n              \"type\": \"text\",\n              \"text\": promptToSend\n            },\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": `data:image/jpeg;base64,${base64String}`\n              }\n            }\n          ]\n        }\n      ],\n      max_tokens: 200\n    };\n\n    try {\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${process.env.REACT_APP_OPENAI_API_KEY}` // Use environment variable for API key\n        },\n        body: JSON.stringify(data)\n      });\n      setUploadProgress(50); // Midway progressgit\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      const apiResponse = await response.json();\n      setUploadProgress(100); // Final progress\n      if (apiResponse.choices && apiResponse.choices.length > 0) {\n        talkmethod(apiResponse.choices[0].message.content);\n        setAPIResult(apiResponse.choices[0].message.content);\n        setStatusMessage('Analysis complete.');     \n      } else {\n        console.error('No choices returned from API');\n        setStatusMessage('Failed to get a response from the API.');\n      }\n    } catch (error) {\n      console.error('Error:', error);\n      alert(error);\n      alert(process.env.REACT_APP_OPENAI_API_KEY);\n      setStatusMessage('An error occurred during the analysis.');\n    }\n  };\n\n  const sendNewPrompt = () => {\n    const newPrompt = prompt + '\\n' + apiResult + '\\n' + speechValue\n    setPrompt(newPrompt)\n    setStatusMessage('Sending request...');\n    setUploadProgress(10); // Initial progress\n    callGPT4(img, newPrompt)\n    alert(newPrompt)\n  };\n\n  const retakeMethod = () => {\n    setImg(null)\n    setStatusMessage('')\n    setAPIResult('')\n    setUploadProgress(0)\n    setPrompt('Imagine that I am a visual impaired individual. Tell me the brand and the object that I am holding. Only describe the object in the foreground. Do not describe the person holding the object.')\n    setSpeechValue('')\n  }\n\n  return (\n    <div className=\"App\">\n      <h1>Sight</h1>\n      <div className=\"Container\">\n      {img === null ? (\n        <>\n          <Webcam\n            audio={false}\n            mirrored={false}\n            height={400}\n            width={400}\n            ref={webcamRef}\n            screenshotFormat=\"image/jpeg\"\n            videoConstraints={videoConstraints}\n          />\n          <button onClick={capture}>Capture photo</button>\n        </>\n      ) : (\n        <>\n          <img src={img} alt=\"screenshot\" />\n          <button onClick={retakeMethod}>Retake</button>\n        </>\n      )}\n    </div>\n      {statusMessage && <p className=\"status-message\">{statusMessage}</p >}\n      {uploadProgress > 0 && (\n        <progress value={uploadProgress} max=\"100\"></progress>\n      )} \n      <p></p>\n      {apiResult && (\n        <div className=\"result\">\n          <strong>Analysis Result:</strong>\n          <textarea value={apiResult} readOnly />\n        </div>\n      )}\n\n      <div className=\"result\">\n       <textarea\n         value={speechValue}\n         onChange={(event) => setSpeechValue(event.target.value)}\n        />\n        <button onMouseDown={listen} onMouseUp={stop}>\n          🎤\n        </button>\n        <button onClick={sendNewPrompt}>\n          Tell me more\n        </button>\n       </div>\n\n    </div>\n  );\n}\nexport default App;"],"mappings":"AAAA,MAAO,CAAAA,KAAK,EAAIC,MAAM,CAAEC,QAAQ,CAAEC,WAAW,CAAEC,SAAS,KAAQ,OAAO,CACvE,MAAO,WAAW,CAClB,MAAO,CAAAC,MAAM,KAAM,cAAc,CACjC,OAASC,oBAAoB,KAAQ,kBAAkB,CACvD,MAAO,CAAAC,OAAO,KAAM,sBAAsB,CAAC,OAAAC,GAAA,IAAAC,IAAA,gCAAAC,QAAA,IAAAC,SAAA,gCAAAC,IAAA,IAAAC,KAAA,yBAE3C,QAAS,CAAAC,GAAGA,CAAA,CAAG,CACb,KAAM,CAACC,WAAW,CAAEC,cAAc,CAAC,CAAGd,QAAQ,CAAC,EAAE,CAAC,CAClD,KAAM,CAAEe,MAAM,CAAEC,IAAK,CAAC,CAAGZ,oBAAoB,CAAC,CAC5Ca,QAAQ,CAAGC,YAAY,EAAK,CAC1BJ,cAAc,CAACI,YAAY,CAAC,CAC9B,CACF,CAAC,CAAC,CAEF,KAAM,CAACC,GAAG,CAAEC,MAAM,CAAC,CAAGpB,QAAQ,CAAC,IAAI,CAAC,CACpC,KAAM,CAAAqB,SAAS,CAAGtB,MAAM,CAAC,IAAI,CAAC,CAC9B,KAAM,CAACuB,SAAS,CAAEC,YAAY,CAAC,CAAGvB,QAAQ,CAAC,EAAE,CAAC,CAC9C,KAAM,CAACwB,aAAa,CAAEC,gBAAgB,CAAC,CAAGzB,QAAQ,CAAC,EAAE,CAAC,CACtD,KAAM,CAAC0B,cAAc,CAAEC,iBAAiB,CAAC,CAAG3B,QAAQ,CAAC,CAAC,CAAC,CACvD,KAAM,CAAC4B,MAAM,CAAEC,SAAS,CAAC,CAAG7B,QAAQ,CAAC,gMAAgM,CAAC,CAEtO,KAAM,CAAA8B,gBAAgB,CAAG,CACvBC,KAAK,CAAE,GAAG,CACVC,MAAM,CAAE,GAAG,CACXC,UAAU,CAAE,MACd,CAAC,CAED,KAAM,CAAAC,OAAO,CAAGjC,WAAW,CAAC,IAAM,CAChC,KAAM,CAAAkC,QAAQ,CAAGd,SAAS,CAACe,OAAO,CAACC,aAAa,CAAC,CAAC,CAClDjB,MAAM,CAACe,QAAQ,CAAC,CAChBV,gBAAgB,CAAC,oBAAoB,CAAC,CACtCE,iBAAiB,CAAC,EAAE,CAAC,CAAE;AACvBW,QAAQ,CAACH,QAAQ,CAAEP,MAAM,CAAC,CAC5B,CAAC,CAAE,CAACP,SAAS,CAAC,CAAC,CAEf,KAAM,CAAAkB,UAAU,CAAIC,UAAU,EAAK,CACjC,KAAM,CAAAC,GAAG,CAAG,GAAI,CAAAC,wBAAwB,CAAC,CAAC,CAC1CD,GAAG,CAACE,IAAI,CAAGH,UAAU,CACrBI,MAAM,CAACC,eAAe,CAACC,KAAK,CAACL,GAAG,CAAC,CACnC,CAAC,CAED,KAAM,CAAAH,QAAQ,CAAG,KAAAA,CAAOS,WAAW,CAAEC,YAAY,GAAK,CACpD,KAAM,CAAAC,YAAY,CAAGF,WAAW,CAACG,OAAO,CAAC,OAAO,CAAE,EAAE,CAAC,CAACA,OAAO,CAAC,MAAM,CAAE,EAAE,CAAC,CAEzE,KAAM,CAAAC,IAAI,CAAG,CACXC,KAAK,CAAE,sBAAsB,CAC7BC,QAAQ,CAAE,CACR,CACE,MAAM,CAAE,MAAM,CACd,SAAS,CAAE,CACT,CACE,MAAM,CAAE,MAAM,CACd,MAAM,CAAEL,YACV,CAAC,CACD,CACE,MAAM,CAAE,WAAW,CACnB,WAAW,CAAE,CACX,KAAK,2BAAAM,MAAA,CAA4BL,YAAY,CAC/C,CACF,CAAC,CAEL,CAAC,CACF,CACDM,UAAU,CAAE,GACd,CAAC,CAED,GAAI,CACF,KAAM,CAAAC,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAAC,4CAA4C,CAAE,CACzEC,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACP,cAAc,CAAE,kBAAkB,CAClC,eAAe,WAAAL,MAAA,CAAYM,OAAO,CAACC,GAAG,CAACC,wBAAwB,CAAG;AACpE,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAACd,IAAI,CAC3B,CAAC,CAAC,CACFxB,iBAAiB,CAAC,EAAE,CAAC,CAAE;AACvB,GAAI,CAAC6B,QAAQ,CAACU,EAAE,CAAE,CAChB,KAAM,IAAI,CAAAC,KAAK,wBAAAb,MAAA,CAAwBE,QAAQ,CAACY,MAAM,CAAE,CAAC,CAC3D,CACA,KAAM,CAAAC,WAAW,CAAG,KAAM,CAAAb,QAAQ,CAACc,IAAI,CAAC,CAAC,CACzC3C,iBAAiB,CAAC,GAAG,CAAC,CAAE;AACxB,GAAI0C,WAAW,CAACE,OAAO,EAAIF,WAAW,CAACE,OAAO,CAACC,MAAM,CAAG,CAAC,CAAE,CACzDjC,UAAU,CAAC8B,WAAW,CAACE,OAAO,CAAC,CAAC,CAAC,CAACE,OAAO,CAACC,OAAO,CAAC,CAClDnD,YAAY,CAAC8C,WAAW,CAACE,OAAO,CAAC,CAAC,CAAC,CAACE,OAAO,CAACC,OAAO,CAAC,CACpDjD,gBAAgB,CAAC,oBAAoB,CAAC,CACxC,CAAC,IAAM,CACLkD,OAAO,CAACC,KAAK,CAAC,8BAA8B,CAAC,CAC7CnD,gBAAgB,CAAC,wCAAwC,CAAC,CAC5D,CACF,CAAE,MAAOmD,KAAK,CAAE,CACdD,OAAO,CAACC,KAAK,CAAC,QAAQ,CAAEA,KAAK,CAAC,CAC9BC,KAAK,CAACD,KAAK,CAAC,CACZC,KAAK,CAACjB,OAAO,CAACC,GAAG,CAACC,wBAAwB,CAAC,CAC3CrC,gBAAgB,CAAC,wCAAwC,CAAC,CAC5D,CACF,CAAC,CAED,KAAM,CAAAqD,aAAa,CAAGA,CAAA,GAAM,CAC1B,KAAM,CAAAC,SAAS,CAAGnD,MAAM,CAAG,IAAI,CAAGN,SAAS,CAAG,IAAI,CAAGT,WAAW,CAChEgB,SAAS,CAACkD,SAAS,CAAC,CACpBtD,gBAAgB,CAAC,oBAAoB,CAAC,CACtCE,iBAAiB,CAAC,EAAE,CAAC,CAAE;AACvBW,QAAQ,CAACnB,GAAG,CAAE4D,SAAS,CAAC,CACxBF,KAAK,CAACE,SAAS,CAAC,CAClB,CAAC,CAED,KAAM,CAAAC,YAAY,CAAGA,CAAA,GAAM,CACzB5D,MAAM,CAAC,IAAI,CAAC,CACZK,gBAAgB,CAAC,EAAE,CAAC,CACpBF,YAAY,CAAC,EAAE,CAAC,CAChBI,iBAAiB,CAAC,CAAC,CAAC,CACpBE,SAAS,CAAC,gMAAgM,CAAC,CAC3Mf,cAAc,CAAC,EAAE,CAAC,CACpB,CAAC,CAED,mBACEH,KAAA,QAAKsE,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClB3E,IAAA,OAAA2E,QAAA,CAAI,OAAK,CAAI,CAAC,cACd3E,IAAA,QAAK0E,SAAS,CAAC,WAAW,CAAAC,QAAA,CACzB/D,GAAG,GAAK,IAAI,cACXR,KAAA,CAAAF,SAAA,EAAAyE,QAAA,eACE3E,IAAA,CAACJ,MAAM,EACLgF,KAAK,CAAE,KAAM,CACbC,QAAQ,CAAE,KAAM,CAChBpD,MAAM,CAAE,GAAI,CACZD,KAAK,CAAE,GAAI,CACXsD,GAAG,CAAEhE,SAAU,CACfiE,gBAAgB,CAAC,YAAY,CAC7BxD,gBAAgB,CAAEA,gBAAiB,CACpC,CAAC,cACFvB,IAAA,WAAQgF,OAAO,CAAErD,OAAQ,CAAAgD,QAAA,CAAC,eAAa,CAAQ,CAAC,EAChD,CAAC,cAEHvE,KAAA,CAAAF,SAAA,EAAAyE,QAAA,eACE3E,IAAA,QAAKiF,GAAG,CAAErE,GAAI,CAACsE,GAAG,CAAC,YAAY,CAAE,CAAC,cAClClF,IAAA,WAAQgF,OAAO,CAAEP,YAAa,CAAAE,QAAA,CAAC,QAAM,CAAQ,CAAC,EAC9C,CACH,CACE,CAAC,CACH1D,aAAa,eAAIjB,IAAA,MAAG0E,SAAS,CAAC,gBAAgB,CAAAC,QAAA,CAAE1D,aAAa,CAAK,CAAC,CACnEE,cAAc,CAAG,CAAC,eACjBnB,IAAA,aAAUmF,KAAK,CAAEhE,cAAe,CAACiE,GAAG,CAAC,KAAK,CAAW,CACtD,cACDpF,IAAA,OAAM,CAAC,CACNe,SAAS,eACRX,KAAA,QAAKsE,SAAS,CAAC,QAAQ,CAAAC,QAAA,eACrB3E,IAAA,WAAA2E,QAAA,CAAQ,kBAAgB,CAAQ,CAAC,cACjC3E,IAAA,aAAUmF,KAAK,CAAEpE,SAAU,CAACsE,QAAQ,MAAE,CAAC,EACpC,CACN,cAEDjF,KAAA,QAAKsE,SAAS,CAAC,QAAQ,CAAAC,QAAA,eACtB3E,IAAA,aACEmF,KAAK,CAAE7E,WAAY,CACnBgF,QAAQ,CAAGC,KAAK,EAAKhF,cAAc,CAACgF,KAAK,CAACC,MAAM,CAACL,KAAK,CAAE,CACxD,CAAC,cACFnF,IAAA,WAAQyF,WAAW,CAAEjF,MAAO,CAACkF,SAAS,CAAEjF,IAAK,CAAAkE,QAAA,CAAC,cAE9C,CAAQ,CAAC,cACT3E,IAAA,WAAQgF,OAAO,CAAET,aAAc,CAAAI,QAAA,CAAC,cAEhC,CAAQ,CAAC,EACL,CAAC,EAEJ,CAAC,CAEV,CACA,cAAe,CAAAtE,GAAG"},"metadata":{},"sourceType":"module","externalDependencies":[]}